# Backend: ollama | openai | anthropic
LLM_BACKEND=ollama

# Ollama (local)
OLLAMA_URL=http://localhost:11434/v1/chat/completions

# API (remote, OpenAI-compatible)
API_URL=https://api.openai.com/v1/chat/completions
API_KEY=

# Model names (override defaults)
MODEL_WRITER=llama3.1:8b
MODEL_PARSER=qwen2.5:7b
MODEL_DOLPHIN=dolphin-mistral
